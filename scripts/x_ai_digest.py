#!/usr/bin/env python3
"""
X AI åšä¸»ç®€æŠ¥ç”Ÿæˆå™¨
ä½¿ç”¨ Bird CLI æŠ“å– X åšä¸»æ¨æ–‡ï¼Œä½¿ç”¨ Claude AI ç”Ÿæˆç®€æŠ¥
"""

import json
import os
import sys
import subprocess
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

import anthropic
import pytz


# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent.parent
CONFIG_PATH = Path(__file__).parent / "config.json"


def load_config() -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(CONFIG_PATH, "r", encoding="utf-8") as f:
        return json.load(f)


def run_bird_command(username: str, count: int = 20) -> str:
    """è¿è¡Œ Bird CLI å‘½ä»¤æŠ“å–æ¨æ–‡"""
    cmd = f"bird user-tweets {username} -n {count}"
    try:
        result = subprocess.run(
            cmd,
            shell=True,
            capture_output=True,
            text=True,
            timeout=60
        )
        if result.returncode == 0:
            return result.stdout
        else:
            print(f"[è­¦å‘Š] @{username} æŠ“å–å¤±è´¥: {result.stderr}")
            return ""
    except subprocess.TimeoutExpired:
        print(f"[è­¦å‘Š] @{username} æŠ“å–è¶…æ—¶")
        return ""
    except Exception as e:
        print(f"[è­¦å‘Š] @{username} æŠ“å–å‡ºé”™: {e}")
        return ""


def parse_bird_output(output: str, blogger_name: str, category: str) -> list:
    """è§£æ Bird CLI è¾“å‡º"""
    tweets = []
    if not output:
        return tweets

    blocks = output.split("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    for block in blocks:
        if not block.strip():
            continue

        lines = block.strip().split("\n")
        if len(lines) < 3:
            continue

        # æå–æ¨æ–‡å†…å®¹
        content_lines = []
        url = ""
        timestamp = ""

        for line in lines[1:]:
            if line.startswith("ğŸ”—"):
                url = line.replace("ğŸ”—", "").strip()
            elif line.startswith("ğŸ“…"):
                timestamp = line.replace("ğŸ“…", "").strip()
            elif line.strip() and not line.startswith("â”Œâ”€"):
                content_lines.append(line)

        content = "\n".join(content_lines).strip()

        if content and len(content) > 50:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
            tweets.append({
                "content": content[:500],  # é™åˆ¶é•¿åº¦
                "url": url,
                "timestamp": timestamp,
                "author": blogger_name,
                "category": category
            })

    return tweets


def fetch_tweets_from_bloggers(config: dict) -> list:
    """ä»æ‰€æœ‰åšä¸»æŠ“å–æ¨æ–‡"""
    feeds_config = config["rss_feeds"]
    all_tweets = []

    def fetch_single_blogger(key, info):
        print(f"  - æŠ“å– @{key}...")
        output = run_bird_command(info["url"], 20)
        tweets = parse_bird_output(output, info["name"], info["category"])
        print(f"    è·å– {len(tweets)} æ¡")
        return tweets

    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = {
            executor.submit(fetch_single_blogger, key, info): key
            for key, info in feeds_config.items()
        }
        for future in as_completed(futures):
            tweets = future.result()
            all_tweets.extend(tweets)

    return all_tweets


def filter_tweets(tweets: list, config: dict) -> list:
    """è¿‡æ»¤æ¨æ–‡"""
    filters = config.get("filters", {})
    min_length = filters.get("min_length", 50)
    exclude_keywords = filters.get("exclude_keywords", [])
    include_keywords = filters.get("include_keywords", [])

    filtered = []
    for tweet in tweets:
        content = tweet.get("content", "")

        # é•¿åº¦æ£€æŸ¥
        if len(content) < min_length:
            continue

        # æ’é™¤å…³é”®è¯
        if any(kw in content for kw in exclude_keywords):
            continue

        # åŒ…å«å…³é”®è¯ï¼ˆå¯é€‰ï¼‰
        if include_keywords:
            if not any(kw in content for kw in include_keywords):
                continue

        filtered.append(tweet)

    return filtered


def prepare_content_for_claude(tweets: list) -> str:
    """å‡†å¤‡å‘é€ç»™ Claude çš„å†…å®¹"""
    sections = []

    # æŒ‰åˆ†ç±»åˆ†ç»„
    by_category = {}
    for tweet in tweets:
        cat = tweet.get("category", "å…¶ä»–")
        if cat not in by_category:
            by_category[cat] = []
        by_category[cat].append(tweet)

    for cat, tweet_list in by_category.items():
        cat_items = []
        for tweet in tweet_list[:10]:  # æ¯åˆ†ç±»æœ€å¤š10æ¡
            content = tweet.get("content", "")
            author = tweet.get("author", "")
            url = tweet.get("url", "")
            cat_items.append(f"- **{author}**: {content}\n  é“¾æ¥: {url}")
        sections.append(f"## {cat}\n" + "\n".join(cat_items))

    return "\n\n".join(sections)


def get_api_key() -> str:
    """è·å– API Key"""
    api_key = os.environ.get("ANTHROPIC_AUTH_TOKEN") or os.environ.get("ANTHROPIC_API_KEY")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® ANTHROPIC_AUTH_TOKEN æˆ– ANTHROPIC_API_KEY ç¯å¢ƒå˜é‡")
    return api_key


def generate_digest_with_claude(content: str, config: dict, today: str) -> str:
    """ä½¿ç”¨ Claude ç”Ÿæˆç®€æŠ¥"""
    api_key = get_api_key()

    base_url = os.environ.get("ANTHROPIC_BASE_URL")
    if base_url:
        client = anthropic.Anthropic(api_key=api_key, base_url=base_url)
    else:
        client = anthropic.Anthropic(api_key=api_key)

    prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ AI é¢†åŸŸå†…å®¹ç¼–è¾‘ï¼Œéœ€è¦æ ¹æ®ä»¥ä¸‹åŸå§‹æ¨æ–‡å†…å®¹ç”Ÿæˆä¸€ä»½ç²¾ç‚¼çš„ä¸­æ–‡ AI åšä¸»ç²¾é€‰ç®€æŠ¥ã€‚

ä»Šå¤©æ—¥æœŸ: {today}

åŸå§‹å†…å®¹:
{content}

## ç”Ÿæˆè¦æ±‚:

### 1. å†…å®¹ç­›é€‰æ ‡å‡†
ä¼˜å…ˆé€‰æ‹©ç¬¦åˆä»¥ä¸‹ç‰¹å¾çš„å†…å®¹:
- **å®ç”¨ä»·å€¼**: æä¾›å…·ä½“çš„å·¥å…·ã€æŠ€å·§ã€å·¥ä½œæµ
- **è§‚ç‚¹ç‹¬åˆ°**: æœ‰æ·±åº¦çš„æ€è€ƒå’Œåˆ†æ
- **æ—¶æ•ˆæ€§å¼º**: æœ€æ–°çš„ AI å·¥å…·å’Œè¶‹åŠ¿
- **ä¼ æ’­æ€§å¼º**: å…·æœ‰è¯é¢˜æ€§å’Œè®¨è®ºä»·å€¼

### 2. æ¿å—ç»“æ„ï¼ˆä¸¥æ ¼æŒ‰ä»¥ä¸‹é¡ºåºï¼‰

**ğŸ¤– ä»Šæ—¥æ‘˜è¦**
- ç”¨ 100 å­—æ¦‚æ‹¬å½“æ—¥æ ¸å¿ƒä¸»é¢˜å’Œçƒ­ç‚¹

**ğŸ› ï¸ AIå·¥å…·ç²¾é€‰ï¼ˆ3-5æ¡ï¼‰**
- Claude Codeã€Cursorã€Copilot ç­‰å·¥å…·çš„æ–°åŠŸèƒ½å’ŒæŠ€å·§
- æ¯æ¡åŒ…å«: [æ ‡é¢˜/æè¿°] + **æ ¸å¿ƒä»·å€¼** + **é€‚ç”¨åœºæ™¯**
- æ§åˆ¶åœ¨ 100 å­—å†…

**âš™ï¸ AIå·¥ä½œæµï¼ˆ3-5æ¡ï¼‰**
- è‡ªåŠ¨åŒ–å·¥ä½œæµçš„è®¾è®¡æ€è·¯å’Œå®ç°
- MCPã€Agentã€Skills ç­‰æ¡†æ¶çš„åº”ç”¨
- æ¯æ¡åŒ…å«: æè¿° + **å®ç°æ–¹å¼** + **æ•ˆæœ**
- æ§åˆ¶åœ¨ 100 å­—å†…

**âœï¸ æç¤ºè¯å·¥ç¨‹ï¼ˆ2-3æ¡ï¼‰**
- é«˜è´¨é‡ Prompt è®¾è®¡æŠ€å·§
- ç»“æ„åŒ–æç¤ºè¯æ–¹æ³•è®º
- æ¯æ¡åŒ…å«: æŠ€å·§/æ–¹æ³• + **åº”ç”¨åœºæ™¯**
- æ§åˆ¶åœ¨ 100 å­—å†…

**ğŸ’» AIç¼–ç¨‹å®è·µï¼ˆ3-5æ¡ï¼‰**
- ä»£ç ç”Ÿæˆã€é‡æ„ã€è°ƒè¯•çš„ AI è¾…åŠ©
- ç¼–ç¨‹å·¥å…·å¯¹æ¯”å’Œé€‰æ‹©
- æ¯æ¡åŒ…å«: å®è·µå†…å®¹ + **å·¥å…·** + **æ•ˆæœ**
- æ§åˆ¶åœ¨ 100 å­—å†…

**ğŸ“ å†…å®¹åˆ›ä½œï¼ˆ2-3æ¡ï¼‰**
- AI è¾…åŠ©å†…å®¹åˆ›ä½œçš„æ–¹æ³•å’Œå·¥å…·
- æå‡åˆ›ä½œæ•ˆç‡çš„æŠ€å·§
- æ¯æ¡åŒ…å«: æ–¹æ³• + **å·¥å…·** + **æ•ˆæœ**
- æ§åˆ¶åœ¨ 100 å­—å†…

**ğŸ§  AIæ€è€ƒä¸åˆ¤æ–­åŠ›ï¼ˆ2-3æ¡ï¼‰**
- å¯¹ AI æ—¶ä»£çš„æ·±åº¦æ€è€ƒ
- åˆ¤æ–­åŠ›æ¯”æŠ€èƒ½æ›´é‡è¦çš„è§‚ç‚¹
- æ¯æ¡åŒ…å«: è§‚ç‚¹ + **åˆ†æ**
- æ§åˆ¶åœ¨ 100 å­—å†…

**ğŸ¯ åšä¸»æ¨è**
åˆ—å‡º 5-10 ä½æœ€å€¼å¾—å…³æ³¨çš„åšä¸»åŠå…¶ä¸“æ³¨é¢†åŸŸ

### 3. é£é™©æç¤ºï¼ˆå¿…é¡»åŒ…å«ï¼‰
```
âš ï¸ **å†…å®¹æç¤º**: æœ¬ç®€æŠ¥å†…å®¹æ¥è‡ª X å¹³å°åšä¸»ï¼Œä»…ä¾›å‚è€ƒã€‚ä½¿ç”¨ AI å·¥å…·æ—¶è¯·æ ¹æ®å®é™…æƒ…å†µåˆ¤æ–­ã€‚
```

### 4. è¯­è¨€é£æ ¼
- ä¸“ä¸šæ€§ä¸å¯è¯»æ€§å¹³è¡¡
- ç®€æ´æ˜äº†ï¼Œç›´å‡»è¦ç‚¹
- æ¯æ¡å†…å®¹æ§åˆ¶åœ¨ 80-100 å­—
- ä½¿ç”¨åŠ ç²—ã€åˆ—è¡¨ç­‰æ–¹å¼æå‡å¯è¯»æ€§

### 5. æ ¼å¼è¦æ±‚
- ä½¿ç”¨ Markdown æ ¼å¼
- å¯¼è¯­ 100 å­—ä»¥å†…
- **ç²¾é€‰å†…å®¹ä¿ç•™åŸæ¨æ–‡é“¾æ¥**
- æ€»é•¿åº¦æ§åˆ¶åœ¨ 2000-3000 å­—

ç›´æ¥è¾“å‡ºç®€æŠ¥å†…å®¹ï¼Œä¸éœ€è¦é¢å¤–è¯´æ˜ã€‚"""

    message = client.messages.create(
        model=config["claude"]["model"],
        max_tokens=config["claude"]["max_tokens"],
        temperature=config.get("claude", {}).get("temperature", 0.3),
        messages=[
            {"role": "user", "content": prompt}
        ]
    )

    return message.content[0].text


def save_digest(content: str, config: dict, today: str):
    """ä¿å­˜ç®€æŠ¥æ–‡ä»¶"""
    digests_dir = PROJECT_ROOT / config["output"]["digests_dir"]
    digests_dir.mkdir(exist_ok=True)

    # ä¿å­˜æ—¥æœŸæ–‡ä»¶
    date_file = digests_dir / f"{today}.md"
    with open(date_file, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"[å®Œæˆ] å·²ä¿å­˜: {date_file}")

    # æ›´æ–° latest.md
    latest_file = digests_dir / "latest.md"
    with open(latest_file, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"[å®Œæˆ] å·²æ›´æ–°: {latest_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("X AI åšä¸»ç²¾é€‰ç®€æŠ¥ç”Ÿæˆå™¨")
    print("=" * 50)

    # åŠ è½½é…ç½®
    config = load_config()

    # è·å–åŒ—äº¬æ—¶é—´æ—¥æœŸ
    tz = pytz.timezone("Asia/Shanghai")
    today = datetime.now(tz).strftime(config["output"]["date_format"])
    print(f"\næ—¥æœŸ: {today}")

    # æŠ“å–æ•°æ®
    print("\n[1/3] æ­£åœ¨æŠ“å– X åšä¸»æ¨æ–‡...")
    tweets = fetch_tweets_from_bloggers(config)
    print(f"      è·å– {len(tweets)} æ¡åŸå§‹æ¨æ–‡")

    # è¿‡æ»¤æ•°æ®
    print("\n[2/3] æ­£åœ¨è¿‡æ»¤å’Œåˆ†ç±»...")
    filtered = filter_tweets(tweets, config)
    print(f"      ç­›é€‰å {len(filtered)} æ¡æ¨æ–‡")

    # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹
    if not filtered:
        print("\n[é”™è¯¯] æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ¨æ–‡ï¼Œé€€å‡º")
        sys.exit(1)

    # å‡†å¤‡å†…å®¹
    raw_content = prepare_content_for_claude(filtered)

    # ç”Ÿæˆç®€æŠ¥
    print("\n[2/3] æ­£åœ¨ä½¿ç”¨ AI ç”Ÿæˆç®€æŠ¥...")
    digest = generate_digest_with_claude(raw_content, config, today)

    # ä¿å­˜
    print("\n[3/3] æ­£åœ¨ä¿å­˜ç®€æŠ¥...")
    save_digest(digest, config, today)

    print("\n" + "=" * 50)
    print("ç”Ÿæˆå®Œæˆ!")
    print("=" * 50)


if __name__ == "__main__":
    main()
